# -*- coding: utf-8 -*-
"""aim2_unsupervised_deepmhci_pan
Work distribution: 
    Gloria mostly worked on the code for unsupervised clustering, which was adapted for SCLC, NSCLC, and pan-cancer datasets.
    Pooja helped with minor edits. 
    ChatGPT was used to generate code for some plots as indicated in comments below.

Automatically generated by Colab from the original ipynb.

Original file is located at
    https://colab.research.google.com/drive/1RvsYtr3FSstQ3t8ymn-hkQRXVpwY83dW
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.decomposition import PCA
import umap
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import silhouette_score

import warnings
warnings.filterwarnings('ignore')

# Load DeepMHC data for neoantigen HLA binders and SCLC subtype label
'''
data format: rows = patients, columns = genes
data file names indicate binding for HLA A, HLA B, and both HLA A and HLA B
'''
# paths to data generated from DeepMHCi, 0.1
data_hla_A_1 = pd.read_csv('/content/drive/Shareddrives/BMI212/Analysis/results_Jun/gene_counts_per_sample_deepmhci_pan_0.1_A.csv', header=0, index_col=0)
data_hla_B_1 = pd.read_csv('/content/drive/Shareddrives/BMI212/Analysis/results_Jun/gene_counts_per_sample_deepmhci_pan_0.1_B.csv', header=0, index_col=0)
data_hla_AB_1 = pd.read_csv('/content/drive/Shareddrives/BMI212/Analysis/results_Jun/gene_counts_per_sample_deepmhci_pan_limit=1_combined.csv', header=0, index_col=0)

data_hla_A_2 = pd.read_csv('/content/drive/Shareddrives/BMI212/Analysis/results_Jun/gene_counts_per_sample_deepmhci_pan_0.2_A.csv', header=0, index_col=0)
data_hla_B_2 = pd.read_csv('/content/drive/Shareddrives/BMI212/Analysis/results_Jun/gene_counts_per_sample_deepmhci_pan_0.2_B.csv', header=0, index_col=0)
data_hla_AB_2 = pd.read_csv('/content/drive/Shareddrives/BMI212/Analysis/results_Jun/gene_counts_per_sample_deepmhci_pan_limit=2_combined.csv', header=0, index_col=0)

data_names_1 = ['Pan: HLA-A, 0.1', 'Pan: HLA-B, 0.1', 'Pan: HLA-A and HLA-B, 0.1']
data_1 = [data_hla_A_1, data_hla_B_1, data_hla_AB_1]

data_names_2 = ['Pan: HLA-A, 0.2', 'Pan: HLA-B, 0.2', 'Pan: HLA-A and HLA-B, 0.2']
data_2 = [data_hla_A_2, data_hla_B_2, data_hla_AB_2]

for data, name in zip(data_1, data_names_1):
  print(f"{name}: {data.shape}")

for data, name in zip(data_2, data_names_2):
  print(f"{name}: {data.shape}")

n_cols = max(len(data_1), len(data_2))

fig, axes = plt.subplots(2, n_cols, figsize=(5 * n_cols, 12))

# ChatGPT was used to generate the plotting code immediately below
# Plot heatmaps for data_1 (binding affinity 0.1)
for idx, (data, name) in enumerate(zip(data_1, data_names_1)):
    ax = axes[0, idx]
    sns.heatmap(data.T, cmap="viridis", ax=ax)
    ax.set_title(f'Heatmap: {name}')
    ax.set_xlabel('Samples')
    ax.set_ylabel('Genes')

# Plot heatmaps for data_2 (binding affinity 0.2)
for idx, (data, name) in enumerate(zip(data_2, data_names_2)):
    ax = axes[1, idx]
    sns.heatmap(data.T, cmap="viridis", ax=ax)
    ax.set_title(f'Heatmap: {name}')
    ax.set_xlabel('Samples')
    ax.set_ylabel('Genes')

plt.tight_layout()
plt.show()

# Scale data
scaler = StandardScaler()

data_hla_A1_scaled = scaler.fit_transform(data_hla_A_1)
data_hla_B1_scaled = scaler.fit_transform(data_hla_B_1)
data_hla_AB1_scaled = scaler.fit_transform(data_hla_AB_1)

data_hla_A2_scaled = scaler.fit_transform(data_hla_A_2)
data_hla_B2_scaled = scaler.fit_transform(data_hla_B_2)
data_hla_AB2_scaled = scaler.fit_transform(data_hla_AB_2)

data_scaled_1 = [data_hla_A1_scaled, data_hla_B1_scaled, data_hla_AB1_scaled]
data_scaled_2 = [data_hla_A2_scaled, data_hla_B2_scaled, data_hla_AB2_scaled]

for data, name in zip(data_scaled_1, data_names_1):
  print(f"{name}: {data.shape}")

for data, name in zip(data_scaled_2, data_names_2):
  print(f"{name}: {data.shape}")

"""#### Clustering: K-Means and DBSCAN"""

# K-Means Clustering
def kmeans(name, X_scaled, k=None):
  scores_list = []
  labels_list = []

  if k is None:
    ks = range(2,11)
  elif k.dtype == int:
    ks = [k]

  print(f'{name} - K-Means:')

  for k in ks:
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(X_scaled)
    sil = silhouette_score(X_scaled, labels)
    scores_list.append(sil)
    labels_list.append(labels)

    print(f'\tk = {k}, Silhouette Score: {sil}')

  return labels_list, scores_list, ks

# DBSCAN Clustering
def dbscan(name, X_scaled):
  dbscan = DBSCAN(eps=0.5, min_samples=5)
  dbscan_labels = dbscan.fit_predict(X_scaled)

  # Silhouette score
  dbscan_valid = dbscan_labels != -1
  if np.unique(dbscan_labels[dbscan_valid]).size > 1:
      dbscan_sil = silhouette_score(X_scaled[dbscan_valid], dbscan_labels[dbscan_valid])
  else:
      dbscan_sil = np.nan

  print(f"{name} - DBSCAN Silhouette Score: {dbscan_sil if not np.isnan(dbscan_sil) else 'Not computable (only one cluster)'}")

  return dbscan_labels, dbscan_sil

def generate_plots(name, kmeans_labels_list, kmeans_scores_list, ks, dbscan_labels, X_pca, X_scaled):
    """
    Generate separate figures for:
    - DBSCAN (single figure)
    - Each K-means label-score pair (each in a figure with PCA and UMAP side by side)
    """
    # DBSCAN plot
    plt.figure(figsize=(7, 5))
    sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=dbscan_labels, palette='Set1')
    plt.title("DBSCAN (PCA Projection)")
    plt.xlabel("PCA 1")
    plt.ylabel("PCA 2")
    plt.legend(title="Cluster", loc='best')
    plt.tight_layout()
    plt.show()

    # K-means plots
    # ChatGPT was used to generate code to format the plots
    for idx, (kmeans_labels, kmeans_score) in enumerate(zip(kmeans_labels_list, kmeans_scores_list)):
        plt.figure(figsize=(14, 5))  

        # PCA Projection
        plt.subplot(1, 2, 1)
        sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=kmeans_labels, palette='Set2')
        plt.title(f"K-means (PCA Projection)\nSilhouette Score: {kmeans_score:.2f}")
        plt.xlabel("PCA 1")
        plt.ylabel("PCA 2")
        plt.legend(title="Cluster", loc='best')

        # UMAP Projection
        plt.subplot(1, 2, 2)
        umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
        X_umap = umap_model.fit_transform(X_scaled)
        sns.scatterplot(x=X_umap[:, 0], y=X_umap[:, 1], hue=kmeans_labels, palette='Set2')
        plt.title("UMAP Projection with K-means Clusters")
        plt.xlabel("UMAP 1")
        plt.ylabel("UMAP 2")
        plt.legend(title="Cluster", loc='best')

        plt.suptitle(f"{name} - K-means Clustering Visualization (k = {ks[idx]})", fontsize=14)
        plt.tight_layout(rect=[0, 0, 1, 1])
        plt.show()

# Perform analyses and generate plots for each dataset

# HLA-A binders
kmeans_labels_A, kmeans_sil_A, ks = kmeans('HLA-A', data_hla_A_scaled, k=None)
dbscan_labels_A, dbscan_sil_A = dbscan('HLA-A', data_hla_A_scaled)
pca_A = PCA(n_components=2)
X_pca_A = pca_A.fit_transform(data_hla_A_scaled)
generate_plots('HLA-A', kmeans_labels_A, kmeans_sil_A, ks, dbscan_labels_A, X_pca_A, data_hla_A_scaled)



# HLA-B binders
kmeans_labels_B, kmeans_sil_B, ks = kmeans('HLA-B', data_hla_B_scaled, k=None)
dbscan_labels_B, dbscan_sil_B = dbscan('HLA-B', data_hla_B_scaled)
pca_B = PCA(n_components=2)
X_pca_B = pca_B.fit_transform(data_hla_B_scaled)
generate_plots('HLA-B', kmeans_labels_B, kmeans_sil_B, ks, dbscan_labels_B, X_pca_B, data_hla_B_scaled)

"""#### PCA before Clustering"""

def kmeans(name, X_scaled, k=None, n_components=50):
  scores_list = []
  labels_list = []

  # Apply PCA to reduce noise before clustering
  pca = PCA(n_components=n_components, random_state=42)
  X_pca = pca.fit_transform(X_scaled)
  print(f'{name} - PCA shape: {X_pca.shape}')

  if k is None:
    ks = range(2, 11)
  elif isinstance(k, int):
    ks = [k]

  print(f'{name} - K-Means after PCA:')

  for k_val in ks:
    kmeans = KMeans(n_clusters=k_val, random_state=42)
    labels = kmeans.fit_predict(X_pca)
    sil = silhouette_score(X_pca, labels)
    scores_list.append(sil)
    labels_list.append(labels)

    print(f'\tk = {k_val}, Silhouette Score: {sil}')

  return labels_list, scores_list, ks

kmeans_labels_A, kmeans_sil_A, ks = kmeans('HLA-A', data_hla_A_scaled, k=None, n_components=5)
kmeans_labels_B, kmeans_sil_B, ks = kmeans('HLA-B', data_hla_B_scaled, k=None, n_components=5)

kmeans_labels_A, kmeans_sil_A, ks = kmeans('HLA-A', data_hla_A_scaled, k=None, n_components=10)
kmeans_labels_B, kmeans_sil_B, ks = kmeans('HLA-B', data_hla_B_scaled, k=None, n_components=10)

kmeans_labels_A, kmeans_sil_A, ks = kmeans('HLA-A', data_hla_A_scaled, k=None, n_components=20)
kmeans_labels_B, kmeans_sil_B, ks = kmeans('HLA-B', data_hla_B_scaled, k=None, n_components=20)

kmeans_labels_A, kmeans_sil_A, ks = kmeans('HLA-A', data_hla_A_scaled, k=None, n_components=30)
kmeans_labels_B, kmeans_sil_B, ks = kmeans('HLA-B', data_hla_B_scaled, k=None, n_components=30)

kmeans_labels_A, kmeans_sil_A, ks = kmeans('HLA-A', data_hla_A_scaled, k=None, n_components=50)
kmeans_labels_B, kmeans_sil_B, ks = kmeans('HLA-B', data_hla_B_scaled, k=None, n_components=50)

kmeans_labels_A, kmeans_sil_A, ks = kmeans('HLA-A', data_hla_A_scaled, k=None, n_components=100)
kmeans_labels_B, kmeans_sil_B, ks = kmeans('HLA-B', data_hla_B_scaled, k=None, n_components=100)

kmeans_labels_A, kmeans_sil_A, ks = kmeans('HLA-A', data_hla_A_scaled, k=None, n_components=200)
kmeans_labels_B, kmeans_sil_B, ks = kmeans('HLA-B', data_hla_B_scaled, k=None, n_components=200)

def dbscan(name, X_scaled, eps=0.5, min_samples=5, n_components=50):
    """
    DBSCAN with PCA preprocessing for noise reduction and faster clustering.

    Parameters:
    - name (str): Identifier for printing results.
    - X_scaled (array-like): Preprocessed data matrix.
    - eps (float): DBSCAN epsilon parameter.
    - min_samples (int): DBSCAN min_samples parameter.
    - n_components (int): Number of PCA components to keep.

    Returns:
    - labels (array): Cluster labels for each sample.
    - dbscan_sil (float): Silhouette score (or NaN if not computable).
    """
    # Apply PCA to reduce noise
    pca = PCA(n_components=n_components, random_state=42)
    X_pca = pca.fit_transform(X_scaled)

    db = DBSCAN(eps=eps, min_samples=min_samples)
    labels = db.fit_predict(X_pca)

    # Count number of clusters (excluding noise label -1)
    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
    n_noise = np.sum(labels == -1)

    print(f"{name} - DBSCAN after PCA (eps={eps}, min_samples={min_samples}):")
    print(f"\tNumber of clusters (excluding noise): {n_clusters}")
    print(f"\tNumber of noise points: {n_noise}")

    # Compute silhouette score (excluding noise points)
    dbscan_valid = labels != -1
    if np.unique(labels[dbscan_valid]).size > 1:
        dbscan_sil = silhouette_score(X_pca[dbscan_valid], labels[dbscan_valid])
    else:
        dbscan_sil = np.nan

    if not np.isnan(dbscan_sil):
        print(f"\tSilhouette Score: {dbscan_sil:.3f}")
    else:
        print("\tSilhouette Score: Not computable (only one cluster present)")

    return labels, dbscan_sil

def generate_plots(name, kmeans_labels_list, kmeans_scores_list, ks, dbscan_labels, X_scaled, n_components_pca=50):
    """
    Generate separate figures for:
    - DBSCAN (single figure with 2D PCA for visualization)
    - Each K-means label-score pair (each in a figure with PCA and UMAP side by side)

    Parameters:
    - name (str): Dataset or experiment name.
    - kmeans_labels_list (list): List of K-means cluster labels.
    - kmeans_scores_list (list): List of silhouette scores for K-means.
    - ks (list): List of K values for K-means.
    - dbscan_labels (array-like): DBSCAN cluster labels.
    - X_scaled (array-like): Scaled data matrix.
    - n_components_pca (int): Number of PCA components for noise reduction (default 50).
    """

    # PCA for visualization (2D)
    pca_vis = PCA(n_components=2, random_state=42)
    X_pca_vis = pca_vis.fit_transform(X_scaled)

    # DBSCAN plot
    plt.figure(figsize=(7, 5))
    unique_labels = set(dbscan_labels)
    for label in unique_labels:
        if label == -1:
            color = 'k'
            marker = 'x'
            label_name = 'Noise'
        else:
            color = None
            marker = 'o'
            label_name = f'Cluster {label}'

        sns.scatterplot(
            x=X_pca_vis[dbscan_labels == label, 0],
            y=X_pca_vis[dbscan_labels == label, 1],
            marker=marker,
            label=label_name,
            s=40
        )
    plt.title("DBSCAN (2D PCA Projection)")
    plt.xlabel("PCA 1")
    plt.ylabel("PCA 2")
    plt.legend(title="Label", loc='best')
    plt.tight_layout()
    plt.show()

    # K-means plots 
    # ChatGPT adapted code from above also adapted here
    for idx, (kmeans_labels, kmeans_score) in enumerate(zip(kmeans_labels_list, kmeans_scores_list)):
        plt.figure(figsize=(14, 5))

        # PCA Projection
        plt.subplot(1, 2, 1)
        sns.scatterplot(x=X_pca_vis[:, 0], y=X_pca_vis[:, 1], hue=kmeans_labels, palette='Set2')
        plt.title(f"K-means (2D PCA Projection)\nSilhouette Score: {kmeans_score:.2f}")
        plt.xlabel("PCA 1")
        plt.ylabel("PCA 2")
        plt.legend(title="Cluster", loc='best')

        # UMAP Projection with PCA first
        pca = PCA(n_components=n_components_pca, random_state=42)
        X_pca = pca.fit_transform(X_scaled)

        umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
        X_umap = umap_model.fit_transform(X_pca)
        plt.subplot(1, 2, 2)
        sns.scatterplot(x=X_umap[:, 0], y=X_umap[:, 1], hue=kmeans_labels, palette='Set2')
        plt.title("UMAP Projection with K-means Clusters")
        plt.xlabel("UMAP 1")
        plt.ylabel("UMAP 2")
        plt.legend(title="Cluster", loc='best')

        plt.suptitle(f"{name} - K-means Clustering Visualization (k = {ks[idx]})", fontsize=14)
        plt.tight_layout(rect=[0, 0, 1, 0.95])
        plt.show()

# Perform analyses and generate plots for each dataset

# HLA-A binders
kmeans_labels_A, kmeans_sil_A, ks = kmeans('HLA-A', data_hla_A_scaled, k=None, n_components=20)
dbscan_labels_A, dbscan_sil_A = dbscan('HLA-A', data_hla_A_scaled)
generate_plots('HLA-A', kmeans_labels_A, kmeans_sil_A, ks, dbscan_labels_A, data_hla_A_scaled)

"""#### PCA before Clustering Pt 2"""

def kmeans(name, X_scaled, k=None, n_components=50):
  scores_list = []
  labels_list = []

  # Apply PCA to reduce noise before clustering
  pca = PCA(n_components=n_components, random_state=42)
  X_pca = pca.fit_transform(X_scaled)
  # print(f'{name} - PCA shape: {X_pca.shape}')

  if k is None:
    ks = range(2, 11)
  elif isinstance(k, int):
    ks = [k]

  # print(f'{name} - K-Means after PCA:')

  for k_val in ks:
    kmeans = KMeans(n_clusters=k_val, random_state=42)
    labels = kmeans.fit_predict(X_pca)
    sil = silhouette_score(X_pca, labels)
    scores_list.append(sil)
    labels_list.append(labels)

    # print(f'\tk = {k_val}, Silhouette Score: {sil}')

  return labels_list, scores_list, ks

def plot_kmeans_scores_projections(data_dict, n_components, kmeans_sil_list_1, kmeans_sil_list_2, ks):
    kmeans_sil_A1, kmeans_sil_B1, kmeans_sil_AB1 = kmeans_sil_list_1
    kmeans_sil_A2, kmeans_sil_B2, kmeans_sil_AB2 = kmeans_sil_list_2
    # ChatGPT was used to generate code to format plots
    # Plot silhouette scores vs k
    plt.figure(figsize=(10, 6))
    plt.plot(ks, kmeans_sil_A1, marker='o', label='HLA-A, limit 0.1')
    plt.plot(ks, kmeans_sil_B1, marker='o', label='HLA-B, limit 0.1')
    plt.plot(ks, kmeans_sil_AB1, marker='o', label='HLA-A and HLA-B, limit 0.1')
    plt.plot(ks, kmeans_sil_A2, marker='o', linestyle='--', label='HLA-A, limit 0.2')
    plt.plot(ks, kmeans_sil_B2, marker='o', linestyle='--', label='HLA-B, limit 0.2')
    plt.plot(ks, kmeans_sil_AB2, marker='o', linestyle='--', label='HLA-A and HLA-B, limit 0.2')
    plt.xlabel('Number of clusters (k)')
    plt.ylabel('Mean Silhouette Score')
    plt.title(f'Pan-cancer: Mean Silhouette Scores by k (PCA n_components = {n_components})')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Create a 3x6 grid (3 projection methods x 6 groups)
    fig, axes = plt.subplots(3, 6, figsize=(24, 12))
    groups = [
        ('HLA-A, 0.1', kmeans_sil_A1, data_dict['HLA-A_0.1']),
        ('HLA-B, 0.1', kmeans_sil_B1, data_dict['HLA-B_0.1']),
        ('HLA-A and HLA-B, 0.1', kmeans_sil_AB1, data_dict['HLA-AB_0.1']),
        ('HLA-A, 0.2', kmeans_sil_A2, data_dict['HLA-A_0.2']),
        ('HLA-B, 0.2', kmeans_sil_B2, data_dict['HLA-B_0.2']),
        ('HLA-A and HLA-B, 0.2', kmeans_sil_AB2, data_dict['HLA-AB_0.2'])
    ]

    projection_methods = {
        'PCA': PCA(n_components=2),
        'UMAP': umap.UMAP(n_components=2, random_state=0),
        't-SNE': TSNE(n_components=2, random_state=0, perplexity=30, learning_rate='auto', init='pca')
    }

    for j, (group_name, sil_scores, data) in enumerate(groups):
        max_idx = int(np.argmax(sil_scores))
        best_k = ks[max_idx]
        best_score = sil_scores[max_idx]

        # Clustering
        kmeans = KMeans(n_clusters=best_k, random_state=0).fit(data)
        labels = kmeans.labels_

        for i, (proj_name, reducer) in enumerate(projection_methods.items()):
            # Dimensionality reduction
            X_proj = reducer.fit_transform(data)

            ax = axes[i, j]
            scatter = ax.scatter(X_proj[:, 0], X_proj[:, 1], c=labels, cmap='tab10', s=30, alpha=0.7)
            ax.set_title(f'{group_name}\n{proj_name}, k={best_k}, Sil={best_score:.3f}')
            ax.set_xlabel(f'{proj_name} 1')
            ax.set_ylabel(f'{proj_name} 2')
            ax.grid(True)

            # Add legend
            unique_labels = np.unique(labels)
            handles = []
            for cluster_id in unique_labels:
                rgba_color = scatter.cmap(scatter.norm(cluster_id))
                handles.append(
                    plt.Line2D([], [], marker='o', color='w', markerfacecolor=rgba_color,
                               label=f'Cluster {cluster_id}', markersize=8, alpha=0.7)
                )
            ax.legend(handles=handles, title='Clusters', loc='upper right')

    plt.tight_layout()
    plt.show()

# limit = 0.1, PCA n components = 2
kmeans_labels_A1, kmeans_sil_A1, ks = kmeans('HLA-A, 0.1', data_hla_A1_scaled, k=None, n_components=2)
kmeans_labels_B1, kmeans_sil_B1, ks = kmeans('HLA-B, 0.1', data_hla_B1_scaled, k=None, n_components=2)
kmeans_labels_AB1, kmeans_sil_AB1, ks = kmeans('HLA-A and HLA-B, 0.1', data_hla_AB1_scaled, k=None, n_components=2)
kmeans_sil_list_1 = [kmeans_sil_A1, kmeans_sil_B1, kmeans_sil_AB1]

# limit = 0.2, PCA n components = 2
kmeans_labels_A2, kmeans_sil_A2, ks = kmeans('HLA-A, 0.2', data_hla_A2_scaled, k=None, n_components=2)
kmeans_labels_B2, kmeans_sil_B2, ks = kmeans('HLA-B, 0.2', data_hla_B2_scaled, k=None, n_components=2)
kmeans_labels_AB2, kmeans_sil_AB2, ks = kmeans('HLA-A and HLA-B, 0.2', data_hla_AB2_scaled, k=None, n_components=2)
kmeans_sil_list_2 = [kmeans_sil_A2, kmeans_sil_B2, kmeans_sil_AB2]


plot_kmeans_scores_projections(data_dict={
        'HLA-A_0.1': data_hla_A1_scaled,
        'HLA-B_0.1': data_hla_B1_scaled,
        'HLA-AB_0.1': data_hla_AB1_scaled,
        'HLA-A_0.2': data_hla_A2_scaled,
        'HLA-B_0.2': data_hla_B2_scaled,
        'HLA-AB_0.2': data_hla_AB2_scaled,
    }, n_components=2,
    kmeans_sil_list_1=(kmeans_sil_A1, kmeans_sil_B1, kmeans_sil_AB1),
    kmeans_sil_list_2=(kmeans_sil_A2, kmeans_sil_B2, kmeans_sil_AB2),
    ks=ks
)

"""#### Clustering with Filtered Dataset"""

# Get the unique, informative genes for a dataset
def get_unique_genes(data, name):
  non_zero_unique_counts = data.apply(lambda col: col[col != 0].nunique())
  informative_genes = non_zero_unique_counts[non_zero_unique_counts > 1]
  informative_genes_df = informative_genes.sort_values(ascending=False).to_frame(name="Unique Non-Zero Values")

  data_filtered = data[informative_genes.index]
  X_filtered_scaled = StandardScaler().fit_transform(data_filtered)

  print(f"{name} - Top Informative Genes:")
  print(informative_genes_df.head)

  # Plots histogram of informative genes
  plt.figure(figsize=(10, 6))
  bins = range(1, int(informative_genes_df["Unique Non-Zero Values"].max()) + 2)
  sns.histplot(informative_genes_df["Unique Non-Zero Values"], bins=bins, kde=False)
  plt.title("Histogram of Unique Non-Zero Values per Gene")
  plt.xlabel("Number of Unique Non-Zero Values")
  plt.ylabel("Number of Genes")
  plt.xticks(bins)
  plt.show()

  return data_filtered, X_filtered_scaled

unique_hla_A_filtered, unique_hla_A_filtered_scaled = get_unique_genes(data_hla_A, 'HLA-A')

# HLA-A binders
kmeans_labels_A, kmeans_sil_A, ks = kmeans('HLA-A', unique_hla_A_filtered_scaled, k=None)
dbscan_labels_A, dbscan_sil_A = dbscan('HLA-A', unique_hla_A_filtered_scaled)
pca_A = PCA(n_components=2)
X_pca_A = pca_A.fit_transform(unique_hla_A_filtered_scaled)
generate_plots('HLA-A', kmeans_labels_A, kmeans_sil_A, ks, dbscan_labels_A, X_pca_A, unique_hla_A_filtered_scaled)

unique_hla_B_filtered, unique_hla_B_filtered_scaled = get_unique_genes(data_hla_B, 'HLA-B')

# HLA-B binders
kmeans_labels_B, kmeans_sil_B, ks = kmeans('HLA-B', unique_hla_B_filtered_scaled, k=None)
dbscan_labels_B, dbscan_sil_B = dbscan('HLA-B', unique_hla_B_filtered_scaled)
pca_B = PCA(n_components=2)
X_pca_B = pca_B.fit_transform(unique_hla_B_filtered_scaled)
generate_plots('HLA-B', kmeans_labels_B, kmeans_sil_B, ks, dbscan_labels_B, X_pca_B, unique_hla_B_filtered_scaled)



"""##### Clustering on Further Filtered Genes"""

# Establish a high signal mask to further filter important genes
def signal_threshold(data, name):
  threshold = 300
  data_filtered, data_filtered_scaled = get_unique_genes(data, name)
  non_zero_counts_per_sample = data_filtered.astype(bool).sum(axis=1).sort_values()

  high_signal_mask = non_zero_counts_per_sample >= threshold
  data_filtered_threshold = data_filtered[high_signal_mask]
  X_filtered_threshold_scaled = StandardScaler().fit_transform(data_filtered_threshold)
  print(f'{name} - data size: {X_filtered_threshold_scaled.shape}')
  print(f'{name} - data size: {data_filtered_threshold.shape}')


  kmeans_filtered_threshold_labels, kmeans_sil, ks = kmeans(name, X_filtered_threshold_scaled, k=None)
  dbscan_filtered_threshold_labels, dbscan_sil = dbscan(name, X_filtered_threshold_scaled)
  pca = PCA(n_components=2)
  X_filtered_threshold_pca = pca.fit_transform(X_filtered_threshold_scaled)
  generate_plots(name, kmeans_filtered_threshold_labels, kmeans_sil, ks, dbscan_filtered_threshold_labels, X_filtered_threshold_pca, X_filtered_threshold_scaled)


# HLA-A binders
signal_threshold(data_hla_A, 'HLA-A')

# HLA-B binders
signal_threshold(data_hla_B, 'HLA-B')

# HLA-A and HLA-B binders
# signal_threshold(data_hla_AB, 'HLA-A and HLA-B')

"""#### Clustering: Hierarchical"""

from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.cluster import AgglomerativeClustering

def hierarchical(name, X_scaled, n_clusters):
    # Compute linkage matrix for dendrogram
    Z = linkage(X_scaled, method='ward')

    # Create subplots for dendrogram and UMAP side by side
    fig, axs = plt.subplots(1, 2, figsize=(14, 5))

    # Dendrogram
    dendrogram(Z, no_labels=True, ax=axs[0])
    axs[0].set_title(f"{name} - Dendrogram")
    axs[0].set_xlabel('Samples')
    axs[0].set_ylabel('Distance')

    # Hierarchical clustering
    hier = AgglomerativeClustering(n_clusters=4)
    labels = hier.fit_predict(X_scaled)
    sil = silhouette_score(X_scaled, labels)
    print(f"Hierarchical Clustering Silhouette Score: {sil}")

    # UMAP plot
    reducer = umap.UMAP(random_state=42)
    embedding = reducer.fit_transform(X_scaled)
    sns.scatterplot(x=embedding[:, 0], y=embedding[:, 1], hue=labels, palette='tab10', ax=axs[1])
    axs[1].set_title(f"{name} - UMAP (Hierarchical)")
    axs[1].set_xlabel('UMAP 1')
    axs[1].set_ylabel('UMAP 2')
    axs[1].legend([],[], frameon=False)  # Remove legend for cleaner view

    plt.tight_layout()
    plt.show()

    return labels, sil

# Perform hierarchical clustering and generate plots for datasets
# HLA-A binders
labels_A, sil_A = hierarchical('HLA-A', data_hla_A_scaled, n_clusters=4)

# HLA-B binders
labels_B, sil_B = hierarchical('HLA-B', data_hla_B_scaled, n_clusters=4)

# Both HLA-A and HLA-B binders
# labels_AB, sil_AB = hierarchical('HLA-A and HLA-B', data_hla_AB_scaled, n_clusters=4)
